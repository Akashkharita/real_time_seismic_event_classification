{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0332717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "from scipy import stats,signal\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from neural_network_architectures import QuakeXNet_2d\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "# Initialize IRIS FDSN client\n",
    "client = Client(\"IRIS\")\n",
    "\n",
    "\n",
    "## setting up some important parameters (not to be changed)\n",
    "num_channels = 3\n",
    "dropout = 0.9\n",
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "model_quakexnet_2d = QuakeXNet_2d(num_classes=4, num_channels=num_channels,dropout_rate=dropout).to(device)  # Use 'cuda' if you have a GPU available\n",
    "\n",
    "# Load the saved model state dict (weights)\n",
    "saved_model_quakexnet_2d = torch.load('../deep_learning_models/best_model_QuakeXNet_2d.pth', map_location=torch.device('cpu'))  # No 'weights_only' argument\n",
    "model_quakexnet_2d.load_state_dict(saved_model_quakexnet_2d)\n",
    "model_quakexnet_2d.to(device)\n",
    "model_quakexnet_2d.eval()\n",
    "\n",
    "\n",
    "model = model_quakexnet_2d\n",
    "model.to('cpu')\n",
    "\n",
    "\n",
    "\n",
    "lowcut = 1\n",
    "highcut = 20\n",
    "nyquist = 0.5 * 50  # Nyquist frequency (original sampling rate is 100 Hz)\n",
    "low = lowcut / nyquist\n",
    "high = highcut / nyquist\n",
    "b, a = signal.butter(4, [low, high], btype='band')  # Bandpass filter coefficients\n",
    "taper_alpha = 0.1\n",
    "fs = 50\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_spectrograms(waveforms = [], fs = 50, nperseg=256, overlap=0.5):\n",
    "    noverlap = int(nperseg * overlap)  # Calculate overlap\n",
    "\n",
    "    # Example of how to get the shape of one spectrogram\n",
    "    f, t, Sxx = signal.spectrogram(waveforms[0, 0], nperseg=nperseg, noverlap=noverlap, fs=fs)\n",
    "\n",
    "    # Initialize an array of zeros with the shape: (number of waveforms, channels, frequencies, time_segments)\n",
    "    spectrograms = np.zeros((waveforms.shape[0], waveforms.shape[1], len(f), len(t)))\n",
    "\n",
    "    for i in range(waveforms.shape[0]):  # For each waveform\n",
    "        for j in range(waveforms.shape[1]):  # For each channel\n",
    "            _, _, Sxx = signal.spectrogram(waveforms[i, j], nperseg=nperseg, noverlap=noverlap, fs=fs)\n",
    "            spectrograms[i, j] = Sxx  # Fill the pre-initialized array\n",
    "\n",
    "    return spectrograms\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Next steps\n",
    "\n",
    "- Run the app.py on the cascadia server. This creates the endpoint from where external apps can acess the results. \n",
    "- Then run this code on the terminal of our local machine - ssh -L 5000:127.0.0.1:5000 -p7777 ak287@cascadia.ess.washington.edu  This allows to connect local machine to the remote server where the flask is running. \n",
    "- And access the results using  http://127.0.0.1:5000/classification on the browser.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Define stations\n",
    "stations = [\"UW.STAR\", \"UW.RCM\"]  # Replace with actual station codes\n",
    "\n",
    "location = '*'\n",
    "channel = '*H*'\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Fetch new waveform data for all stations (last 60 seconds)\n",
    "        start_time = UTCDateTime() - 200\n",
    "        end_time = UTCDateTime() - 50\n",
    "\n",
    "        station_results = {}\n",
    "\n",
    "        for station in stations:\n",
    "            network, station = station.split('.')\n",
    "            st = client.get_waveforms(network, station, location, channel, start_time, end_time)\n",
    "            st.resample(50)\n",
    "\n",
    "            # Process data\n",
    "            data = np.array([st[i].data[0:5000] for i in range(3)]).reshape([1,3,5000])\n",
    "            tapered_data = np.array([np.multiply(signal.windows.tukey(data.shape[-1], alpha=taper_alpha), row) for row in data])\n",
    "            filtered_data = np.array([signal.filtfilt(b, a, row) for row in tapered_data])\n",
    "            norm = np.std(abs(filtered_data), axis=2)\n",
    "            normalized_data = (filtered_data / norm[:, :, None])\n",
    "\n",
    "            specs = extract_spectrograms(normalized_data)\n",
    "\n",
    "            # Run classification\n",
    "            with torch.no_grad():\n",
    "                output = model(torch.Tensor(specs))\n",
    "                softmax_probs = F.softmax(output, dim=1).cpu().numpy()\n",
    "\n",
    "            # Get class labels\n",
    "            class_labels = [\"earthquake\", \"explosion\", \"noise\", \"surface event\"]\n",
    "            max_class_index = np.argmax(softmax_probs[0])  # Index of max probability class\n",
    "            max_class_label = class_labels[max_class_index]\n",
    "\n",
    "            # Store results\n",
    "            station_results[station] = {\n",
    "                \"timestamp\": start_time.isoformat(),\n",
    "                \"probabilities\": {\n",
    "                    \"earthquake\": float(softmax_probs[0][0]),\n",
    "                    \"explosion\": float(softmax_probs[0][1]),\n",
    "                    \"noise\": float(softmax_probs[0][2]),\n",
    "                    \"surface event\": float(softmax_probs[0][3])\n",
    "                },\n",
    "                \"max_label\": max_class_label\n",
    "            }\n",
    "\n",
    "        # Check if UW.STAR and UW.RCM are both NOT classified as \"noise\"\n",
    "        if (station_results[\"STAR\"][\"max_label\"] != \"noise\" and \n",
    "            station_results[\"RCM\"][\"max_label\"] != \"noise\"):\n",
    "\n",
    "            # **Append new result directly to file in JSONL format**\n",
    "            with open(\"realtime_classification.json\", \"a\") as f:\n",
    "                f.write(json.dumps(station_results) + \"\\n\")  # Write new entry as a single line\n",
    "\n",
    "            #print(\"Updated classification:\", station_results)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "    time.sleep(20)  # Wait 2 seconds before fetching new data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surface",
   "language": "python",
   "name": "surface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
